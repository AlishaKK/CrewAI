

### **Prompt Chaining â€“ Simple Explanation**  

**What is it?**  
Prompt chaining breaks a big task into **smaller, connected steps**, where each LLM output becomes the input for the next step. This improves accuracy but may take more time.  
![image](https://github.com/user-attachments/assets/bba5be5c-f28f-499f-b20c-e6a9f9546e9f)


### **How it Works:**  
1. **Step 1:** One LLM does the first part of the task.  
2. **Step 2:** The output is checked (optional "gate" to ensure correctness).  
3. **Step 3:** Another LLM continues based on the previous output.  

### **When to Use It?**  
âœ… When a task can be divided into **clear, fixed steps**.  
âœ… When you need **higher accuracy** and donâ€™t mind a bit more time.  

### **Examples:**  
1ï¸âƒ£ **Marketing Copy â†’ Translation**  
   - First LLM: Writes marketing content.  
   - Second LLM: Translates it into another language.  

2ï¸âƒ£ **Document Writing Process**  
   - First LLM: Creates an outline.  
   - "Gate" checks if the outline is good.  
   - Second LLM: Writes the full document based on the outline.



---

### **ğŸš€ How It Works (Step-by-Step)**  
1ï¸âƒ£ **AI generates a topic** â†’ âœï¸ Example: "Future of AI in 2025."  
2ï¸âƒ£ **AI uses that topic** â†’ ğŸ“ Creates a blog outline based on it.  
3ï¸âƒ£ **Results are linked** â†’ ğŸ”„ One response feeds into the next.  

---

### **ğŸ’¡ Simple Code Example: AI Generates a Topic & Outline**  

```python
from crewai.flow.flow import Flow, start, listen
from litellm import completion  

class TopicOutlineFlow(Flow):
    model = "gpt-4o-mini"

    @start()  # Step 1: AI generates a topic
    def generate_topic(self):
        response = completion(
            model=self.model,
            messages=[{"role": "user", "content": "Suggest a creative blog topic for 2025."}]
        )
        topic = response["choices"][0]["message"]["content"].strip()
        print(f"\nğŸ“ Blog Topic: {topic}")
        return topic

    @listen(generate_topic)  # Step 2: AI creates an outline from the topic
    def generate_outline(self, topic):
        response = completion(
            model=self.model,
            messages=[{"role": "user", "content": f"Create a detailed outline for a blog on '{topic}'."}]
        )
        outline = response["choices"][0]["message"]["content"].strip()
        print("\nğŸ“Œ Blog Outline:\n", outline)
        return outline

if __name__ == "__main__":  # ğŸš€ Run the process
    flow = TopicOutlineFlow()
    final_outline = flow.kickoff()
    print("\nâœ… Final Blog Outline:\n", final_outline)
```

---

### **ğŸ¯ What Happens?**  
âœ”ï¸ **AI picks a topic** â†’ ğŸ“Œ **AI builds an outline from it** â†’ ğŸ”— **Each step connects to the next!**  




