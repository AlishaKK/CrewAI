

---

### **Agentic System**  
A system that independently makes decisions and takes actions to achieve goals.  

- **Workflow:**  
  - Follows predefined steps, not autonomous.  
  - Uses pre-selected LLMs/tools controlled by code.  
  - Executes fixed paths to complete tasks.
    
- **Agent:**  
  - Self-directed and autonomous.  
  - Dynamically selects LLMs/tools.  
  - Makes real-time decisions to complete tasks.  

 

---

### **CrewAI**  
A framework that enables AI agents to collaborate and solve problems as a team.  

#### **Core Components of CrewAI:**  
1. **Crew** – The leader that organizes the team and manages the workflow.  
2. **AI Agents** – Specialized workers (e.g., researcher, writer) handling tasks.  
3. **Process** – The workflow system that assigns tasks and ensures smooth execution.  
4. **Tasks** – Small steps that collectively achieve the main goal.

   

#### **Flows in CrewAI:**  
Structured frameworks that integrate tasks and Crews to design, execute, and manage AI workflows seamlessly.  

---


---

### **Why Use Flows?**  
- Automates AI workflows by chaining multiple tasks together.  
- Manages state to share and track data across different steps.  
- Uses event-driven execution, ensuring tasks run dynamically when needed.  
- Provides flexible control with conditions, loops, and branching logic.  
- Simplifies workflow creation, making complex AI automation easier.  

---

### **Decorators in CrewAI Flows**  
✅ **@start()** → Marks a method as the starting point of a Flow, executing it when the Flow begins.  
✅ **@listen()** → Marks a method as a listener, triggering it when a specific task produces an output.  

---


---

## **Flows, Crews, and Agents: A Framework for Efficient Workflow**
1. **Flows** → Manage the overall workflow, ensuring smooth coordination.  
2. **Crews** → Organize and direct Agents, promoting teamwork and goal alignment.  
3. **Agents** → Execute Tasks using Tools, handling the actual work.  

---

## **CrewAI Flows: Output & State Management**  
🔹 **Final Output** → The last executed method returns the final result using `kickoff()`.  
🔹 **State Management** → Saves and shares data between tasks for smooth execution.  
🔹 **Importance** → Ensures continuity, dependency handling, and efficient AI workflows.  

---

## **Flow State Management**  
- **Unstructured State** → Can be changed freely without strict rules.  
  - **Use when**: You need flexibility, and the state changes frequently.  
- **Structured State** → Follows a predefined structure for consistency.  
  - **Use when**: You need stability, rules, and better development tools.  
✅ **Unstructured = Flexibility** | ✅ **Structured = Control & Safety**  

---

## **Flow Persistence**  
The `@persist` decorator saves the state of your flow, ensuring it remains intact even after restarts.  

🔹 **Class-Level Persistence** → Saves state for all methods automatically.  
🔹 **Method-Level Persistence** → Saves state only for specific methods.  

### **How It Works:**  
✅ Each flow has a unique ID.  
✅ State is stored in an SQLite database by default.  
✅ State is automatically reloaded after restarts or failures.  
**Use `@persist` to maintain your flow's state across runs.**  

---

## **Flow Control in CrewAI**  
1. **or_** → Runs a method if *any* of the listed methods finish.  
2. **and_** → Runs a method *only if all* the listed methods finish.  
3. **@router** → Determines the next step based on a method’s output.  

🚀 These tools make your workflow **smarter, dynamic, and more efficient!**  

---

# **Creating a CrewAI Flow with LiteLLM**  

### **1️⃣ Create Flow**  
```bash
crewai create flow <flow_name>
```

### **2️⃣ Setup**  
- `crews/` → Define agents & tasks.  
- `main.py` → Build Flow using `@start` & `@listen`.  

### **3️⃣ Install & Run**  
```bash
uv venv && source .venv/bin/activate  # Create & activate virtual env  
uv add litellm  # Install LiteLLM  
uv run kickoff  # Run Flow  
```

---

## **LiteLLM Integration in CrewAI**  
**Install:**  
```bash
uv add litellm
```

**Use in `main.py`:**  
```python
from crewai.flow.flow import Flow, start, listen
from litellm import completion  

class MyFlow(Flow):
    model = "gpt-4o-mini"

    @start()
    def generate_text(self):
        return completion(model=self.model, messages=[{"role": "user", "content": "Blog idea for 2025?"}])["choices"][0]["message"]["content"].strip()

    @listen(generate_text)
    def expand_idea(self, text):
        return completion(model=self.model, messages=[{"role": "user", "content": f"Expand: {text}"}])["choices"][0]["message"]["content"].strip()

if __name__ == "__main__":
    print(MyFlow().kickoff())
```

✅ **LiteLLM Benefits:** Easy model switching, cost-efficient, Gemini-compatible. 🚀


